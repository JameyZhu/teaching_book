# 8.1 Machine Learning with R

## 1. Practice Guide

Here we use random forest as an example.

### 1) preparation

we need to install the following packages:

1.  `dplyr`: manipulate data frame
2.  `randomForest`: build random forest model
3.  `ROCR`: ROC analysis
4.  `GGally`: plot correlation between features

<!-- -->

```r
install.packages(c('dplyr', 'randomForest', 'ROCR', 'GGally'))
```

To avoid conflict of function name, in the following code, I will try me
best to use `pkg::fun()` instead of `library(pkg)`.

Before we start, let set the random seed to make our results
reproducible:

    set.seed(0) 

### 2) generate data set

We use one of R’s built-in data set, `iris`, Edgar Anderson’s Iris Data
set.

The original data set contains observations for four features (sepal
length and width, and petal length and width — all in cm) of 150 flowers
of three species (each 50).

To make things simple, here we only choose two species, `versicolor` and
`virginica`.

```r
df <- iris[iris$Species != 'setosa', ]
rownames(df) <- NULL;
df$Species <- factor(df$Species)
```

> -   The first line selects rows in `iris` whose species is not `setosa`, so only `versicolor` and `virginica` are left.
> -   The second lines remvoes row names of `df`, which is not needed.
> -   The third line drops factor level of `Species` variable, `randomForest::randomForest()` would complain if you don’t do this. (This is a little technical, the orignial `Species` contains three levels, `setosa`, `versicolor` and `virginica`. Although we remove all `setosa` values, the `setosa` level still exists, and now this level contains no values, that would cause `randomForest::randomForest()` to fail . After we call `factor()`, `Species` contains only two levels, both do have values.)

Let’s have a look at our data (only part of it is shown, the whole data
contains 100 rows):

```r
head(df, 3)
```
```
##   Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
## 1          7.0         3.2          4.7         1.4 versicolor
## 2          6.4         3.2          4.5         1.5 versicolor
## 3          6.9         3.1          4.9         1.5 versicolor
```

```r
tail(df, 3)
```
```
##     Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
## 98           6.5         3.0          5.2         2.0 virginica
## 99           6.2         3.4          5.4         2.3 virginica
## 100          5.9         3.0          5.1         1.8 virginica
```


### 3) divide data set

Before we build the model, we need to divide the data set into training
set and testing set. So we can train our model using data in training
set, and evalute the model using data in testing set.

Here we randomly assigns 80 percent samples to the training set, and the
left 20 percent to the testing set.


```r
nrow_training <- floor(nrow(df) * 0.8)  # Calculate the size of training sets
indexes <- sample(1:nrow(df), nrow_training)  # these rows will be select for training

training <- df[indexes, ] 
testing <- df[-indexes, ]
```

The code seems a little complicated, and it require you to be familiar
with the R language.

Anyway, I will try to use a simple example to explain the core idea:

> -   Image your data contains only 5 rows, the 80 percent is 5 \* 0.8 = 4 (in that case `nrow_training` is `4`).
> -   Image you decide to choose the 1st, 2nd, 3rd and 5th rows for training (in that case `indexes` is `c(1, 2, 3, 5)`)
> -   Now `training` contains the 1st, 2nd, 3rd and 5th rows of `df` (`[indexes, ]` means to choose these rows)
> -   And `testing` contains the 4th row of `df` (`[-indexes, ]` means not to choose these rows, so only the 4th row is left)

### 4) Build the model

Then we can build a random forest model.

```r
rf_classifier = randomForest::randomForest(Species ~ ., training)
```

The code is fairly easy and straightforward:

> -   `Species` is the reponse variable
> -   `.` tells that all other variables are features
> -   `training` is the data to train the model

Let’s have a look at our model

```r
rf_classifier
```
```
## 
## Call:
##  randomForest(formula = Species ~ ., data = training) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 7.5%
## Confusion matrix:
##            versicolor virginica class.error
## versicolor         38         3  0.07317073
## virginica           3        36  0.07692308
```


### 5) Evaluate the model

After we build the model, we can make prediction on the testing set:

```r
predicted_value <- predict(rf_classifier, testing[, -ncol(testing)])
real_value <- testing[[ncol(testing)]]
```

> -   `predict()` needs two arguments, the model and a `data.frame` of features. (`-ncol(testing)` means to drop the last column, so `testing[, -ncol(testing)` only contains features)
> -   we use `testing[[ncol(testing)]]` to get the last column, i.e, the real value of `Species` in the testing set


```r
predicted_value
```
```
##          8         11         15         18         32         33 
## versicolor versicolor versicolor versicolor versicolor versicolor 
##         44         47         50         53         55         57 
## versicolor versicolor versicolor  virginica  virginica versicolor 
##         65         68         71         73         89         94 
##  virginica  virginica  virginica  virginica versicolor  virginica 
##         97        100 
##  virginica  virginica 
## Levels: versicolor virginica
```

```r
real_value
```
```
##  [1] versicolor versicolor versicolor versicolor versicolor versicolor
##  [7] versicolor versicolor versicolor virginica  virginica  virginica 
## [13] virginica  virginica  virginica  virginica  virginica  virginica 
## [19] virginica  virginica 
## Levels: versicolor virginica
```

As you can see, `predicted_value` and `real_value` both contains 20
values, correspond to 20 rows of testing data. Each value tells a row
belongs which species, the former is the model’ precdiction, the latter
is the real case.

I manually reformat the result to make it more clear:

<table style="width:57%;">
<colgroup>
<col style="width: 25%" />
<col style="width: 18%" />
<col style="width: 13%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">predicted_value</th>
<th style="text-align: center;">real_value</th>
<th style="text-align: center;">correct</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="even">
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="odd">
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="even">
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="odd">
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="even">
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="odd">
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="even">
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="odd">
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="even">
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="odd">
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="even">
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">FALSE</td>
</tr>
<tr class="odd">
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="even">
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="odd">
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="even">
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="odd">
<td style="text-align: center;">versicolor</td>
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">FALSE</td>
</tr>
<tr class="even">
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="odd">
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">TRUE</td>
</tr>
<tr class="even">
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">virginica</td>
<td style="text-align: center;">TRUE</td>
</tr>
</tbody>
</table>

And we can summarise the result into a confusion matrix:

<table>
<thead>
<tr class="header">
<th> </th>
<th>True versicolor</th>
<th>True virginica</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Predicted versicolor</td>
<td>9</td>
<td>2</td>
</tr>
<tr class="even">
<td>Predicted virginica</td>
<td>0</td>
<td>9</td>
</tr>
</tbody>
</table>

Now we can calculate some statistics:

-   sensitivity: 9 / (9+0) = 100%
-   specificity: 9 / (9+2) = 82%
-   accuracy: (9 + 9)/20 = 90%

    <!-- > - mcc (Matthews correlation coefficient): (9\*9 - 0\*2) / (9\*11\*11\*9) = 0.008 > -->

### 6) ROC

Finally, let’s draw a ROC curve.

```r
probability <- predict(rf_classifier, testing[, -ncol(testing)], type = 'prob')
label <- ifelse(testing[[5]] ==  levels(testing[[5]])[1], 1, 0)

prediction <- ROCR::prediction(probability[, 1], label)
```

> -   `probability`: for each row, we use the model to predict the probability of it belongs to each species
> -   `levels`: we flag `versicolor` as `1`, `virginica` as `0`
> -   `prediction`: we calculate the ROC

```r
roc <- ROCR::performance(prediction, 'tpr', 'fpr') 
ROCR::plot(roc, main = 'ROC Curve') 
```

> -   Plot the ROC using false positive rate (`'fpr'`) as x axis, true positive rate (`'tpr'`) as y axis.

![](8.1-machine-learning-with-r2_files/figure-markdown_strict/plot-roc-1.png)

Cauculate the AUC

```r
ROCR::performance(prediction, 'auc')@y.values[[1]]
```
```
## [1] 0.989899
```


### 7) Tips and more

#### 7a) feature correlation

Before we build the model, we usually need to examine our data first. A
good start is to explore the correlation between features:

```r
GGally::ggpairs(df, columns = 1:4, ggplot2::aes(color = Species))
```

![](8.1-machine-learning-with-r2_files/figure-markdown_strict/unnamed-chunk-10-1.png)

### 8) More reading

The code refer [this
post](https://www.blopig.com/blog/2017/04/a-very-basic-introduction-to-random-forests-using-r/)

For more machine learning models, you can refer to [these
scripts](https://github.com/urluzhi/scripts/tree/master/Rscript/machine_learning):

-   `logistic_regression.R`: Logistic Regression
-   `svm.R`: SVM
-   `plot_result.R`: Plot your training and testing performance

Last but not the least, you can also read *[The `caret`
package](http://topepo.github.io/caret)*, a tutorial written in GitBook

## 2. Homework

-   学习和使用教程中的代码，使用下面的数据，练习Random
    Forest，在training set上训练，在test set上预测，汇报模型的prediction
    performance: 包括 accuracy, sensitivity, specificity,
    roc\_auc等指标，绘制ROC曲线。

    > **作业要求** ：上交一个文档汇报prediction
    > performance，并解释如上指标所代表的意义，附ROC曲线并解释其意义。

We use another R’s built-in dataset, `mtcars`, you need to run the
following code to contruct the data:

```r
df2 <- mtcars
df2$Transmission <- factor(ifelse(df2$am, 'manual', 'automatic'))
df2 <- df2[ , c('disp', 'hp', 'drat', 'wt', 'qsec', 'Transmission')]
```

> -   `am` variable stores information of transmission of the car as integer, `1` means “manual”, `0` means “automatic”. we transform it into a factor and stores it into a new variable, `Transmission`
> -   then we select six columns: `disp`, `hp`, `drat`, `wt`, `qsec`, `Transmission`

```r
head(df2)
```

<table style="width:100%;">
<colgroup>
<col style="width: 33%" />
<col style="width: 10%" />
<col style="width: 7%" />
<col style="width: 8%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 19%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"> </th>
<th style="text-align: center;">disp</th>
<th style="text-align: center;">hp</th>
<th style="text-align: center;">drat</th>
<th style="text-align: center;">wt</th>
<th style="text-align: center;">qsec</th>
<th style="text-align: center;">Transmission</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>Mazda RX4</strong></td>
<td style="text-align: center;">160</td>
<td style="text-align: center;">110</td>
<td style="text-align: center;">3.9</td>
<td style="text-align: center;">2.62</td>
<td style="text-align: center;">16.46</td>
<td style="text-align: center;">manual</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Mazda RX4 Wag</strong></td>
<td style="text-align: center;">160</td>
<td style="text-align: center;">110</td>
<td style="text-align: center;">3.9</td>
<td style="text-align: center;">2.875</td>
<td style="text-align: center;">17.02</td>
<td style="text-align: center;">manual</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>Datsun 710</strong></td>
<td style="text-align: center;">108</td>
<td style="text-align: center;">93</td>
<td style="text-align: center;">3.85</td>
<td style="text-align: center;">2.32</td>
<td style="text-align: center;">18.61</td>
<td style="text-align: center;">manual</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Hornet 4 Drive</strong></td>
<td style="text-align: center;">258</td>
<td style="text-align: center;">110</td>
<td style="text-align: center;">3.08</td>
<td style="text-align: center;">3.215</td>
<td style="text-align: center;">19.44</td>
<td style="text-align: center;">automatic</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>Hornet Sportabout</strong></td>
<td style="text-align: center;">360</td>
<td style="text-align: center;">175</td>
<td style="text-align: center;">3.15</td>
<td style="text-align: center;">3.44</td>
<td style="text-align: center;">17.02</td>
<td style="text-align: center;">automatic</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Valiant</strong></td>
<td style="text-align: center;">225</td>
<td style="text-align: center;">105</td>
<td style="text-align: center;">2.76</td>
<td style="text-align: center;">3.46</td>
<td style="text-align: center;">20.22</td>
<td style="text-align: center;">automatic</td>
</tr>
</tbody>
</table>

In this data, we have five features:

1.  `disp`: Displacement (cu.in.)
2.  `hp`: Gross horsepowe
3.  `drat`: Rear axle ratio
4.  `wt`: Weight (1000 lbs)
5.  `qsec`: 1/4 mile time

And the reponse variable is `Transmission`.
